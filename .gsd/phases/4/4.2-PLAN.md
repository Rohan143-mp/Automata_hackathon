---
phase: 4
plan: 2
wave: 1
---

# Plan 4.2: Local TTS Service

## Objective
Convert the final English intent (generated by Ollama) into spoken audio playback locally on the PC Hub.

## Context
- .gsd/SPEC.md
- hub/main_server.py (From Phase 3)

## Tasks

<task type="auto">
  <name>Implement Python TTS Service</name>
  <files>hub/services/voice_service.py</files>
  <action>
    - Ensure a cross-platform TTS library is available (`pyttsx3` is recommended as it operates entirely offline).
    - Create a Python function `speak_text(text, pitch=1.0, speed=1.0)`.
    - Function should initialize the local TTS engine, apply the basic speed, and block while playing the audio synchronously (since speech is the climax of the loop).
    - (Note: `pyttsx3` has limited pitch control natively, so we'll focus primarily on `rate` / speed for affective resonance below, but stub the pitch argument for now).
  </action>
  <verify>python -m py_compile hub/services/voice_service.py</verify>
  <done>Python script successfully initializes local text-to-speech rendering.</done>
</task>

<task type="auto">
  <name>Enable TTS in Main Server</name>
  <files>hub/main_server.py</files>
  <action>
    - Import `speak_text` into `main_server.py`.
    - Directly after broadcasting telemetry in the main loop, call `speak_text(speech, speed=1.0)`.
  </action>
  <verify>python -m py_compile hub/main_server.py</verify>
  <done>Generated sentences from Ollama are now audibly spoken by the PC Hub.</done>
</task>

## Success Criteria
- [ ] PC Hub can audibly speak without relying on cloudy APIs (like Google TTS).
