---
phase: 4
plan: 3
wave: 2
---

# Plan 4.3: Affective Resonance Heart Rate Modulator

## Objective
The Bio-Digital Larynx relies on translating the student's internal emotional state (measured via heart rate) into the tone and speed of the synthetic voice, granting them the ability to "sound" excited, anxious, or calm.

## Context
- .gsd/SPEC.md
- hub/services/voice_service.py (from Plan 4.2)
- hub/main_server.py (from Phase 3)

## Tasks

<task type="auto">
  <name>Implement Heart Rate Pitch/Rate Curves</name>
  <files>hub/services/affective_resonance.py</files>
  <action>
    - Create a Python script exporting `calculate_vocal_params(heart_rate)`.
    - Map the raw analog HR integer from the Glove (typically 60-150 BPM) into a speed ratio.
    - Example Thresholds:
      - `< 65 BPM`  (Calm): Return `speed = 0.85`
      - `65–85 BPM` (Normal): Return `speed = 1.0`
      - `85–100 BPM` (Engaged): Return `speed = 1.15`
      - `> 100 BPM` (Excited): Return `speed = 1.30`
  </action>
  <verify>python -m py_compile hub/services/affective_resonance.py</verify>
  <done>Algorithm maps a BPM integer to a float multiplier according to spec.</done>
</task>

<task type="auto">
  <name>Wire Affective Resonance into Main Loop</name>
  <files>hub/main_server.py</files>
  <action>
    - Import `calculate_vocal_params` into `main_server.py`.
    - In the main matching loop, extract the current `hr` value that was parsed from the Glove's CSV payload.
    - Calculate the dynamic speed: `speed = calculate_vocal_params(hr)`.
    - Pass this speed into the `speak_text(speech, speed=speed)` invocation locally.
    - Update the `broadcast_telemetry` payload to include the current `hr`.
  </action>
  <verify>python -m py_compile hub/main_server.py</verify>
  <done>The generated TTS speed demonstrably speeds up when the heart rate rises in the mock stream.</done>
</task>

## Success Criteria
- [ ] Synthetic voice is no longer static; it possesses a proxy for emotion.
