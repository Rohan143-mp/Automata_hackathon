# Architecture — SYNAPSE

> Evolved from HealthGuard. Auto-generated by /map, refined during deep project rethink.

## Overview

SYNAPSE (formerly HealthGuard) is a **full-duplex communication suit** for deaf-mute students. It combines a Flutter mobile app with IoT hardware (smart glove) and on-device AI to translate gestures into fluent, emotion-modulated speech while transcribing classroom audio locally.

The existing HealthGuard vitals infrastructure (Health Connect, backend sync, AI chat/coaching, spike alerts) is **fully preserved** and serves as the health-monitoring backbone.

## System Layers

```
┌─────────────────────────────────────────────────────┐
│               HARDWARE LAYER                         │
│  Arduino Uno ← Flex×5 + MPU6050 + Pulse Sensor      │
│       │ Serial                                       │
│  ESP8266 NodeMCU → WebSocket over WiFi               │
│       │                                              │
│  Bone Conduction Transducer ← PAM8403 Amp ← Phone   │
└───────┼──────────────────────────────────────────────┘
        │
┌───────┼──────────────────────────────────────────────┐
│       │        FLUTTER APP LAYER                      │
│       │                                              │
│  ┌────┴────────────────────────────────────────┐     │
│  │   NEW SYNAPSE SERVICES                       │    │
│  │                                              │    │
│  │  TelemetryService   — WebSocket client       │    │
│  │  WhisperService     — Local whisper.cpp STT  │    │
│  │  GestureEngine      — 7D cosine similarity   │    │
│  │  IntentService      — Gemini context gen     │    │
│  │  VoiceService       — HR-modulated TTS       │    │
│  └──────────────────────────────────────────────┘    │
│                                                      │
│  ┌──────────────────────────────────────────────┐    │
│  │   EXISTING HEALTHGUARD SERVICES (Preserved)  │    │
│  │                                              │    │
│  │  HealthService      — Health Connect vitals  │    │
│  │  ApiService         — Backend REST client    │    │
│  │  ChatService        — Gemini AI chat         │    │
│  │  CoachingService    — Gemini coaching plans  │    │
│  │  SpikeAlertService  — HR emergency alerts    │    │
│  └──────────────────────────────────────────────┘    │
└──────────────────────────────────────────────────────┘
        │
┌───────┼──────────────────────────────────────────────┐
│       │        BACKEND LAYER (Existing)               │
│  Node.js + Express + SQLite                          │
│  Tables: Doctor, Patient, Vitals, Appointments       │
│  Routes: /patient, /doctor                           │
└──────────────────────────────────────────────────────┘
```

## New Components (SYNAPSE)

### Services

| Service | File | Purpose |
|---------|------|---------|
| WhisperService | `services/whisper_service.dart` | On-device whisper.cpp STT via `whisper_ggml_plus` |
| TelemetryService | `services/telemetry_service.dart` | WebSocket client receiving glove sensor data |
| GestureEngine | `services/gesture_engine.dart` | 7D vector cosine similarity matching |
| IntentService | `services/intent_service.dart` | Gesture intent + context → Gemini → fluent sentence |
| VoiceService | `services/voice_service.dart` | HR-modulated TTS output via `flutter_tts` |

### Models

| Model | File | Purpose |
|-------|------|---------|
| HardwareTelemetry | `models/hardware_telemetry.dart` | Parsed sensor data (flex×5, gyro×2, HR) |
| GestureMatch | `models/gesture_match.dart` | Matched gesture with confidence score |

### Screens

| Screen | File | Purpose |
|--------|------|---------|
| ClassroomScreen | `features/classroom/classroom_screen.dart` | Whisper STT live transcript |
| GloveDebugScreen | `features/glove/glove_debug_screen.dart` | Raw sensor visualization |
| GloveScreen | `features/glove/glove_screen.dart` | Gesture → speech main interface |
| SynapseScreen | `features/synapse/synapse_screen.dart` | Unified demo mode |

### Assets

| Asset | Purpose |
|-------|---------|
| `ggml-tiny.en.bin` | Whisper model (downloaded to device storage, ~75MB) |
| `gesture_library.json` | Reference gesture vectors for cosine similarity |

## Existing Components (HealthGuard — Preserved)

### Features
Auth, Dashboard, Chat Assistant, Coaching, Vitals, Reminders, Profile, Book Appointment

### Models
UserVitals, VitalReading, BloodPressureReading, ChatMessage, CoachingPlan, RiskResult

### Services
HealthService, ApiService, ChatService, CoachingService, SpikeAlertService

### Backend
Express + SQLite with Doctor/Patient/Vitals/Appointments tables

## New Dependencies

| Package | Version | Purpose |
|---------|---------|---------|
| whisper_ggml_plus | ^1.3.3 | On-device Whisper inference |
| web_socket_channel | ^3.0.3 | WebSocket connection to ESP8266 |
| record | ^5.1.2 | Audio recording for Whisper input |
| path_provider | ^2.1.2 | Temp file storage for audio and model |

## Technical Debt (Carried Forward)

- [ ] Gemini API key hardcoded in `config/ai_config.dart`
- [ ] Passwords stored in plaintext (no hashing)
- [ ] No JWT/session management
- [ ] `google_generative_ai` in dev_dependencies instead of dependencies
- [ ] No automated tests
